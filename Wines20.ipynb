{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ox-SVd3Y8CjA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above command is used to import all the necessary libraries."
      ],
      "metadata": {
        "id": "AmNrOliggZft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('wines_SPA.csv')"
      ],
      "metadata": {
        "id": "hDQ6F64VhWbg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line is added to load your data into a pandas DataFrame named df."
      ],
      "metadata": {
        "id": "ZmSVwgR2h3QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'type'\n",
        "\n",
        "\n",
        "X = df.drop(columns=target_column)\n",
        "y = df[target_column]\n",
        "\n",
        "\n",
        "\n",
        "numerical_features = X.select_dtypes(include=['number']).columns\n",
        "\n",
        "\n",
        "X_numerical = X[numerical_features]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numerical, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "b_u2TthGinIs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above commands perpares the data for machine learning model by:\n",
        "1.Selecting numerical features: Focuses on numerical data suitable for scaling.\n",
        "2.Scaling features: Standardizes numerical features to a similar range.\n",
        "3.Splitting data: Prepares data for training and evaluating a machine learning model."
      ],
      "metadata": {
        "id": "zRrRF0fX3WYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary Imports\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "\n",
        "imputer_y = SimpleImputer(strategy='most_frequent')\n",
        "y_train = imputer_y.fit_transform(y_train.reshape(-1, 1))\n",
        "y_train = y_train.ravel()\n",
        "\n",
        "# Use Logistic Regression for classification (increase max_iter to avoid convergence issues)\n",
        "lr = LogisticRegression(max_iter=200)  # Increased the max_iter to 200\n",
        "lr.fit(X_train_scaled, y_train)  # Fit model with imputed and scaled data\n",
        "y_pred_lr = lr.predict(X_test_scaled)  # Make predictions on test set\n",
        "\n",
        "# Check types of y_test and y_pred_lr\n",
        "print(\"y_test type:\", type(y_test))\n",
        "print(\"y_pred_lr type:\", type(y_pred_lr))\n",
        "\n",
        "# Ensure y_test and y_pred_lr are both strings or both numeric\n",
        "y_test = y_test.astype(str)  # Convert to strings if necessary\n",
        "y_pred_lr = y_pred_lr.astype(str)  # Convert to strings if necessary\n",
        "\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_lr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOk3tnVs3poM",
        "outputId": "20a57f60-2252-4128-f4fd-60a7bc0f3a4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test type: <class 'pandas.core.series.Series'>\n",
            "y_pred_lr type: <class 'numpy.ndarray'>\n",
            "Logistic Regression Accuracy: 0.5513333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is used to perform logistic regression."
      ],
      "metadata": {
        "id": "c9-gd59C70qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Precision (macro average):\", precision_score(y_test, y_pred_dt, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFnolMCd8GMC",
        "outputId": "e73487ce-fcf5-4316-a449-ce1a1582bce3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.8\n",
            "Precision (macro average): 0.4758459366645635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above commands are used to make decision trees."
      ],
      "metadata": {
        "id": "As9YGyRp84Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision (macro average):\", precision_score(y_test, y_pred_rf, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl3zUv4i8--u",
        "outputId": "16c82e39-17c4-4c15-a311-93fe23f22c7c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8146666666666667\n",
            "Precision (macro average): 0.5484754512326666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The commands calculate precision for a multiclass classification dataset."
      ],
      "metadata": {
        "id": "ZWIneFLs-AS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Precision (macro average):\", precision_score(y_test, y_pred_svm, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjhXsBhh-K_I",
        "outputId": "ed27a36a-4033-41aa-f5ea-0f99feaf94e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.5466666666666666\n",
            "Precision (macro average): 0.24666697778197919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is used to form a Support Vector Machine."
      ],
      "metadata": {
        "id": "LrEMJSJ_-dGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"Precision (macro average):\", precision_score(y_test, y_pred_knn, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3tqxTol-nEW",
        "outputId": "9eec1a61-ec9a-4a9c-c486-2e96ba71ae65"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.808\n",
            "Precision (macro average): 0.506148218539852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code performs KNN.\n",
        "K-Nearest Neighbors (KNN) is a simple and powerful algorithm for classification and regression tasks. It is most effective when the data has a clear, consistent pattern and when you can compute distances easily. However, it can be computationally expensive for large datasets and sensitive to feature scaling, which makes preprocessing crucial."
      ],
      "metadata": {
        "id": "BXdNs4Q6-9fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "# Impute missing values using the 'mean' strategy (replace NaNs with the mean value of each column)\n",
        "imputer = SimpleImputer(strategy='mean')  # For numerical data\n",
        "X_train_imputed = imputer.fit_transform(X_train)  # Fit and transform on training data\n",
        "X_test_imputed = imputer.transform(X_test)  # Only transform on test data\n",
        "\n",
        "# Now train the Gradient Boosting model\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train_imputed, y_train)  # Fit model on imputed training data\n",
        "y_pred_gb = gb.predict(X_test_imputed)  # Predict on imputed test data\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "\n",
        "# If multiclass, make sure to adjust precision scoring to handle multiple classes\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_gb, average='macro'))  # Adjust 'average' if needed for your data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYMJh78_Vlt",
        "outputId": "67032d74-36c3-400c-b0be-cb1c61a6e7dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 0.8166666666666667\n",
            "Precision: 0.5009857771647923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code performs Gradient Boosting that is a powerful ensemble learning technique that combines multiple weak learners (usually shallow decision trees) to create a strong, highly accurate model. It works by training a sequence of models, each focusing on correcting the errors of the previous model. Despite its high accuracy,"
      ],
      "metadata": {
        "id": "rYqme0QrBcwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_test, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "SfP06KrHDF63"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code For all the models it  can calculate common metrics such as accuracy, precision, recall, F1-score, and confusion matrix."
      ],
      "metadata": {
        "id": "rss1jrKlDkZG"
      }
    }
  ]
}